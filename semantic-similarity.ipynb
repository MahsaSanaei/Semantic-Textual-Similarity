{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23372,"status":"ok","timestamp":1668587258354,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"IS4XeH-Y0GGr","outputId":"a8186c2b-0257-4374-9dea-425871e5bc90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53646,"status":"ok","timestamp":1668587314462,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"tjA1-J1KSh1n","outputId":"7fd71cb1-e6ac-4e47-9ce2-c2517aa1a231"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 30.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 51.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 73.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hazm\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[K     |████████████████████████████████| 316 kB 24.1 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 71.3 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 49.8 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394488 sha256=e037f3d711c0ae19b2319a0c646c8941bc13b7927a8af4d26ca33a890f0a6c02\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154936 sha256=8bca10247d4ea7c1192a95e4beaac003f71d190612e0511d5a8bbf6ea25c5a5b\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.7\n","    Uninstalling nltk-3.7:\n","      Successfully uninstalled nltk-3.7\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting advertools\n","  Downloading advertools-0.13.2-py2.py3-none-any.whl (310 kB)\n","\u001b[K     |████████████████████████████████| 310 kB 23.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from advertools) (1.3.5)\n","Collecting scrapy>=2.5.0\n","  Downloading Scrapy-2.7.1-py2.py3-none-any.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 66.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from advertools) (6.0.1)\n","Collecting twython>=3.8.0\n","  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n","Requirement already satisfied: pyasn1>=0.4 in /usr/local/lib/python3.7/dist-packages (from advertools) (0.4.8)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->advertools) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->advertools) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->advertools) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->advertools) (1.15.0)\n","Collecting pyOpenSSL>=21.0.0\n","  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 6.8 MB/s \n","\u001b[?25hCollecting cssselect>=0.9.1\n","  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n","Collecting itemadapter>=0.1.0\n","  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n","Collecting itemloaders>=1.0.1\n","  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n","Collecting zope.interface>=5.1.0\n","  Downloading zope.interface-5.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n","\u001b[K     |████████████████████████████████| 254 kB 60.1 MB/s \n","\u001b[?25hCollecting cryptography>=3.3\n","  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n","\u001b[K     |████████████████████████████████| 4.1 MB 58.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools) (21.3)\n","Collecting service-identity>=18.1.0\n","  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools) (4.9.1)\n","Collecting PyDispatcher>=2.0.5\n","  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n","Collecting protego>=0.1.15\n","  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n","Collecting Twisted>=18.9.0\n","  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 50.4 MB/s \n","\u001b[?25hCollecting parsel>=1.5.0\n","  Downloading parsel-1.7.0-py2.py3-none-any.whl (14 kB)\n","Collecting queuelib>=1.4.2\n","  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n","Collecting w3lib>=1.17.0\n","  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n","Collecting tldextract\n","  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n","\u001b[K     |████████████████████████████████| 93 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools) (57.4.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->scrapy>=2.5.0->advertools) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->scrapy>=2.5.0->advertools) (2.21)\n","Collecting jmespath>=0.9.5\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (0.2.8)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools) (22.1.0)\n","Collecting constantly>=15.1\n","  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n","Collecting Automat>=0.8.0\n","  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools) (4.1.1)\n","Collecting incremental>=21.3.0\n","  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n","Collecting hyperlink>=17.1.1\n","  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy>=2.5.0->advertools) (2.10)\n","Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from twython>=3.8.0->advertools) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython>=3.8.0->advertools) (1.3.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython>=3.8.0->advertools) (2022.9.24)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools) (3.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->scrapy>=2.5.0->advertools) (3.0.9)\n","Collecting requests-file>=1.4\n","  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy>=2.5.0->advertools) (3.8.0)\n","Building wheels for collected packages: PyDispatcher\n","  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11959 sha256=c0313c4b9bc33a388a3426bc39d572c9eaa7d3fb724cffa9f023144f3b55600a\n","  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d\n","Successfully built PyDispatcher\n","Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, twython, scrapy, advertools\n","Successfully installed Automat-22.10.0 PyDispatcher-2.0.6 Twisted-22.10.0 advertools-0.13.2 constantly-15.1.0 cryptography-38.0.3 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.7.0 protego-0.2.1 pyOpenSSL-22.1.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.7.1 service-identity-21.1.0 tldextract-3.4.0 twython-3.9.1 w3lib-2.0.1 zope.interface-5.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting parsivar\n","  Downloading parsivar-0.2.3.tar.gz (36.2 MB)\n","\u001b[K     |████████████████████████████████| 36.2 MB 139 kB/s \n","\u001b[?25hCollecting nltk==3.4.5\n","  Downloading nltk-3.4.5.zip (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 43.0 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->parsivar) (1.15.0)\n","Building wheels for collected packages: parsivar, nltk\n","  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parsivar: filename=parsivar-0.2.3-py3-none-any.whl size=36492971 sha256=6d329590b52c6b0f791a29fafd7659f07bf94e8df1a03f77218a9ff263fe2496\n","  Stored in directory: /root/.cache/pip/wheels/ae/67/7a/49cbf08f64d3f76a26eceaf0e481a40e233f05d4356875cbed\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449922 sha256=22a523226f55ad750edaeeca3763cc433273f01905d1d3bfd4aac1588aba7d26\n","  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n","Successfully built parsivar nltk\n","Installing collected packages: nltk, parsivar\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.3\n","    Uninstalling nltk-3.3:\n","      Successfully uninstalled nltk-3.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","hazm 0.7.0 requires nltk==3.3, but you have nltk 3.4.5 which is incompatible.\u001b[0m\n","Successfully installed nltk-3.4.5 parsivar-0.2.3\n"]}],"source":["!pip3 install transformers\n","!pip3 install hazm\n","!pip3 install advertools\n","!pip3 install parsivar"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"V6vffAuH0q7z","executionInfo":{"status":"ok","timestamp":1668587324207,"user_tz":-210,"elapsed":7811,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from hazm import *\n","import advertools as adv\n","from parsivar import Tokenizer\n","from transformers import BertTokenizer\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from transformers import BertModel, BertForSequenceClassification\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"DFtJk5iaSNTI","executionInfo":{"status":"ok","timestamp":1668587327242,"user_tz":-210,"elapsed":6,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YUTfzG7z08Lh","executionInfo":{"status":"ok","timestamp":1668587330425,"user_tz":-210,"elapsed":2787,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["train = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/study plan/Projects/Project 1/data/Train-word.csv\", sep='\\t')\n","val = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/study plan/Projects/Project 1/data/Val-word.csv\", sep='\\t')\n","test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/study plan/Projects/Project 1/data/Test-word.csv\", sep='\\t')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668587332048,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"_ZKVg6lK1VI2","outputId":"9f4f5a15-c960-436a-96f7-1cb220bdc971"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set Information\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7266 entries, 0 to 7265\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   premise     7266 non-null   object\n"," 1   hypothesis  7266 non-null   object\n"," 2   label       7266 non-null   object\n","dtypes: object(3)\n","memory usage: 170.4+ KB\n","None \n","\n","missing values\n","premise       0\n","hypothesis    0\n","label         0\n","dtype: int64 \n","\n","duplicated rows\n","0 \n","\n","train shape\n","(7266, 3)\n"]}],"source":["print('Training set Information')\n","print(train.info(), \"\\n\")\n","print('missing values')\n","print(train.isnull().sum(), \"\\n\")\n","print('duplicated rows')\n","print(train.duplicated().sum(), \"\\n\")\n","data = train.drop_duplicates(keep='first')\n","print('train shape')\n","print(train.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668587333564,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"MzGKnrwu108p","outputId":"4b03a8e4-9b99-4390-cef2-f148ab36402b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation set Information\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1537 entries, 0 to 1536\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   premise     1537 non-null   object\n"," 1   hypothesis  1537 non-null   object\n"," 2   label       1537 non-null   object\n","dtypes: object(3)\n","memory usage: 36.1+ KB\n","None \n","\n","missing values\n","premise       0\n","hypothesis    0\n","label         0\n","dtype: int64 \n","\n","duplicated rows\n","0 \n","\n","validation shape\n","(1537, 3)\n"]}],"source":["print('Validation set Information')\n","print(val.info(), \"\\n\")\n","print('missing values')\n","print(val.isnull().sum(), \"\\n\")\n","print('duplicated rows')\n","print(val.duplicated().sum(), \"\\n\")\n","data = val.drop_duplicates(keep='first')\n","print('validation shape')\n","print(val.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668587334029,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"nZ-MSrLQ2Gce","outputId":"62b14e2e-0f5b-4b81-83fa-4f186b14e533"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test set Information\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1564 entries, 0 to 1563\n","Data columns (total 5 columns):\n"," #   Column            Non-Null Count  Dtype \n","---  ------            --------------  ----- \n"," 0   premise           1564 non-null   object\n"," 1   hypothesis        1564 non-null   object\n"," 2   label             1564 non-null   object\n"," 3   hard(hypothesis)  1564 non-null   int64 \n"," 4   hard(overlap)     1564 non-null   int64 \n","dtypes: int64(2), object(3)\n","memory usage: 61.2+ KB\n","None \n","\n","missing values\n","premise             0\n","hypothesis          0\n","label               0\n","hard(hypothesis)    0\n","hard(overlap)       0\n","dtype: int64 \n","\n","duplicated rows\n","0 \n","\n","test shape\n","(1564, 5)\n"]}],"source":["print('Test set Information')\n","print(test.info(), \"\\n\")\n","print('missing values')\n","print(test.isnull().sum(), \"\\n\")\n","print('duplicated rows')\n","print(test.duplicated().sum(), \"\\n\")\n","data = test.drop_duplicates(keep='first')\n","print('test shape')\n","print(test.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668587345863,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"zg1DmxaA2Noo","outputId":"c817fc02-f936-4b59-8ef1-526d64fa7789"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             premise  \\\n","0  اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...   \n","1  اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...   \n","2  اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...   \n","\n","                                          hypothesis label  \n","0  نخستین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی...     e  \n","1  کانون های جغرافیایی مصر، اندلس و شام، نخستین ر...     c  \n","2  سیسیل بعد از اسپانیا بزرگ ترین کانونی بود که ه...     n  "],"text/html":["\n","  <div id=\"df-b149286e-4fc8-45e7-a09f-155483da8ce1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>premise</th>\n","      <th>hypothesis</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...</td>\n","      <td>نخستین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی...</td>\n","      <td>e</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...</td>\n","      <td>کانون های جغرافیایی مصر، اندلس و شام، نخستین ر...</td>\n","      <td>c</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...</td>\n","      <td>سیسیل بعد از اسپانیا بزرگ ترین کانونی بود که ه...</td>\n","      <td>n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b149286e-4fc8-45e7-a09f-155483da8ce1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b149286e-4fc8-45e7-a09f-155483da8ce1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b149286e-4fc8-45e7-a09f-155483da8ce1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["train.head(3)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1668587348276,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"mrLpGT0M4gwb","outputId":"09e82f82-20d3-413f-8635-6a592bb275ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             premise  \\\n","0  دوران امامت امام صادق علیه السلام، مصادف است ب...   \n","1  دوران امامت امام صادق علیه السلام، مصادف است ب...   \n","2  با شهادت امام رضا(ع) مرحله جدیدی از تلاش ائمه ...   \n","\n","                                          hypothesis label  hard(hypothesis)  \\\n","0  امام سجاد (ع) در دورانی امامت کردند که همزمان ...     c                 0   \n","1  دستگاه فاسد حکومتی با صرف هزینه های هنگفت، سعی...     n                 1   \n","2  دوران محنت اهل بیت پس از شهادت امام رضا(ع) آغا...     e                 0   \n","\n","   hard(overlap)  \n","0              1  \n","1              0  \n","2              0  "],"text/html":["\n","  <div id=\"df-d798060d-a646-4efc-a2d2-6bf3089b9138\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>premise</th>\n","      <th>hypothesis</th>\n","      <th>label</th>\n","      <th>hard(hypothesis)</th>\n","      <th>hard(overlap)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>دوران امامت امام صادق علیه السلام، مصادف است ب...</td>\n","      <td>امام سجاد (ع) در دورانی امامت کردند که همزمان ...</td>\n","      <td>c</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>دوران امامت امام صادق علیه السلام، مصادف است ب...</td>\n","      <td>دستگاه فاسد حکومتی با صرف هزینه های هنگفت، سعی...</td>\n","      <td>n</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>با شهادت امام رضا(ع) مرحله جدیدی از تلاش ائمه ...</td>\n","      <td>دوران محنت اهل بیت پس از شهادت امام رضا(ع) آغا...</td>\n","      <td>e</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d798060d-a646-4efc-a2d2-6bf3089b9138')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d798060d-a646-4efc-a2d2-6bf3089b9138 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d798060d-a646-4efc-a2d2-6bf3089b9138');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["test.head(3)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1668587351560,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"mnu9aZk54kSW","outputId":"d85b2d91-928c-40ba-9650-4ece4146a42a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train label: \n"," n    2448\n","e    2429\n","c    2389\n","Name: label, dtype: int64 \n","\n","Validation label: \n"," n    523\n","e    515\n","c    499\n","Name: label, dtype: int64 \n","\n","Test label: \n"," n    535\n","e    519\n","c    510\n","Name: label, dtype: int64\n"]}],"source":["print(\"Train label: \\n\", train['label'].value_counts(), \"\\n\")\n","print(\"Validation label: \\n\", val['label'].value_counts(), \"\\n\")\n","print(\"Test label: \\n\", test['label'].value_counts())"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"WfTLC7g6IOK1","executionInfo":{"status":"ok","timestamp":1668587352824,"user_tz":-210,"elapsed":4,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["LABELS_TO_IDS = {label: ids for ids, label in enumerate(list(set(train['label'].tolist())))}\n","IDS_TO_LABELS = {ids: label for label, ids in LABELS_TO_IDS.items()}"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668587353667,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"BLlWHDWsIYoH","outputId":"b33102aa-870b-475d-f559-2cc767c62b63"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'c': 0, 'n': 1, 'e': 2}\n","{0: 'c', 1: 'n', 2: 'e'}\n"]}],"source":["print(LABELS_TO_IDS)\n","print(IDS_TO_LABELS)"]},{"cell_type":"markdown","source":["##Preprocessing"],"metadata":{"id":"qe2GM40XArNi"}},{"cell_type":"code","source":["class Preprocessing():\n","\n","  def __init__(self, normalizer, tokenizer, lemmatizer, stopwords:list, punc:list):\n","    \"\"\"\n","        Class initializer\n","    Args:\n","        stopwords(list): list of stop words\n","        punc(list): list of punctuations\n","    Returns:\n","    \"\"\"\n","    self.normalizer = normalizer\n","    self.tokenizer = tokenizer\n","    self.lemmatizer = lemmatizer\n","    self.stopwords = stopwords\n","    self.punc = punc\n","\n","  def normalize(self,X:str) -> str:\n","    \"\"\"\n","        Normalizing\n","    Args:\n","        X(str): input string\n","    Return:\n","        X(str): string normalized\n","    \"\"\"\n","    return self.normalizer.normalize(X)\n","\n","  def tokenize(self,X:str) -> list:\n","    \"\"\"\n","        Tokenization\n","    Args:\n","        X(str): input string\n","    Returns:\n","        tokens(list): list of words\n","    \"\"\"\n","    return self.tokenizer.tokenize_words(X)\n","  \n","  def lema(self,X:list) -> list:\n","    \"\"\"\n","        Lemmatization\n","    Args:\n","        X(list): list of words\n","    Returns:\n","        X(list): list of words lemmatized\n","    \"\"\"\n","    return [self.lemmatizer.lemmatize(word) for word in X]\n","\n","  def stopword_removal(self,X:list) -> list:\n","    \"\"\"\n","        Stopword removal\n","    Args:\n","        X(list): list of words\n","    Returns:\n","        X(list): list of words that stopwords removed\n","    \"\"\"\n","    return [token for token in X if token[0] not in self.stopwords]\n","  \n","  def join_sents(self,X:list) -> str:\n","    \"\"\"\n","        Sentences creation\n","    Args:\n","        X(list): list of words\n","    Returns:\n","        X(str): sentence created\n","    \"\"\"\n","    sents = ' '.join([token for token in X])\n","    return sents.strip()\n","\n","  def punc_removal(self,X:str) -> str:\n","    \"\"\"\n","        Punctuation removal\n","    Args:\n","        X(str): input string\n","    Returns:\n","        X(str): string that punctuations removed\n","    \"\"\"\n","    for ele in X:\n","        if ele in self.punc:\n","            X = X.replace(ele, \"\")\n","    return X \n","  \n","  def preprocessor(self,X:str) -> str:\n","    \"\"\"\n","         Data Preprocessor\n","    Args:\n","        X(str): input string\n","    Return:\n","        X(str): preprocessed string\n","    \"\"\"\n","    #Normalizing\n","    X = self.normalize(X)\n","    #Tokenization\n","    X = self.tokenize(X)\n","    #Lemmatization\n","    X = self.lema(X)\n","    #Stopword_removal\n","    X = self.stopword_removal(X)\n","    #Sentences creation\n","    X = self.join_sents(X)\n","    #Punchuation removal\n","    X = self.punc_removal(X)\n","    return X"],"metadata":{"id":"JpRWtJY0YP3S","executionInfo":{"status":"ok","timestamp":1668587356808,"user_tz":-210,"elapsed":2,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["normalizer = Normalizer()\n","tokenizer = Tokenizer()\n","lemmatizer = Lemmatizer()\n","stopwords = sorted(adv.stopwords['persian'])\n","punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~1234567890؟۱۲۳۴۵۶۷۸۹۰''' "],"metadata":{"id":"MJ4NzoDMJT1M","executionInfo":{"status":"ok","timestamp":1668587358824,"user_tz":-210,"elapsed":7,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["Preprocess = Preprocessing(normalizer, tokenizer, lemmatizer, stopwords, punc)"],"metadata":{"id":"dN7-cvLKgO7X","executionInfo":{"status":"ok","timestamp":1668587359279,"user_tz":-210,"elapsed":4,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train['premise'] = [Preprocess.preprocessor(text) for text in train['premise']]\n","train['hypothesis'] = [Preprocess.preprocessor(text) for text in train['hypothesis']]"],"metadata":{"id":"7LXbWtayWMZK","executionInfo":{"status":"ok","timestamp":1668587368911,"user_tz":-210,"elapsed":5049,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["val['premise'] = [Preprocess.preprocessor(text) for text in val['premise']]\n","val['hypothesis'] = [Preprocess.preprocessor(text) for text in val['hypothesis']]"],"metadata":{"id":"I4oqJecmWxSp","executionInfo":{"status":"ok","timestamp":1668587372223,"user_tz":-210,"elapsed":1967,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["test['premise'] = [Preprocess.preprocessor(text) for text in test['premise']]\n","test['hypothesis'] = [Preprocess.preprocessor(text) for text in test['hypothesis']]"],"metadata":{"id":"_E84DRW-YkzK","executionInfo":{"status":"ok","timestamp":1668587374429,"user_tz":-210,"elapsed":699,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["##Tokenization & Dataset & DataLoader"],"metadata":{"id":"Jz7qmZPaynvn"}},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1190,"status":"ok","timestamp":1668587377373,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"51Bu_ezt4s_-","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["734720fed4fc4f37b30bbab21d408196","0f6de2a1f2c848d1bf84666fde36960d","3450f318c8d54bbe916708c75d83aea3","dcfe3f8d05eb4f06a372eef7e75689cd","590d989e8e344abe8bf45cc6a16b9224","84f1109546ca41209eb29e48ebf568a8","8eaf32825a4745f687410bd7cedf127a","d6a2dcf306a24672810df589da799398","9b125f273e494c8e9f717f5edd99e6d9","798ff23a32c641e49206d73382d81d1d","ce16cb36025043409bf47502078f7854","e2243c5125424610a684e984389fedba","4b3ffcb6b5c84e4295905b8db65d7f43","2d8cfc6cf7b14e70982c03ce05a59596","a3926770478547c3b48950c1e7b9ab8f","feef64b87bd549a783535d1d38ce690c","4fea59c806d8471c8268e73571d2682a","aea8d8aec1f14ff3af42fe49b0be4db4","fb3965e51c0c40f1990b65385dd5ab07","61f08537449f464a9a274b3fbcbda789","ba9a8633883c4d2fb76a7d63cde23aad","146f08edaf2742d48f7fa5ca93d4dbe4"]},"outputId":"0a217640-62e9-44fc-dfe1-f4731846bcde"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"734720fed4fc4f37b30bbab21d408196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/434 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2243c5125424610a684e984389fedba"}},"metadata":{}}],"source":["tokenizer = BertTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"cCY-M-LUIOqa","executionInfo":{"status":"ok","timestamp":1668587379028,"user_tz":-210,"elapsed":2,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["max_len = 128\n","train_batch_size = 32\n","val_batch_size = 32\n","test_batch_size = 32"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"50p9Jt2wISYW","executionInfo":{"status":"ok","timestamp":1668587388329,"user_tz":-210,"elapsed":454,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_len, labels_to_ids):\n","        self.len = len(data)\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        self.labels_to_ids = labels_to_ids\n","       \n","    def __len__(self):\n","        return self.len\n","             \n","    def __getitem__(self, index):\n","        text1 = ' '.join(self.data['premise'].tolist()[index].split())\n","        text2 = ' '.join(self.data['hypothesis'].tolist()[index].split())\n","        label = self.data['label'].tolist()[index]\n","        inputs = self.tokenizer.encode_plus(text1,\n","                                            text2,\n","                                            max_length=self.max_len,\n","                                            padding='max_length',\n","                                            return_token_type_ids=True,\n","                                            truncation=True)\n","        label = self.labels_to_ids[label]\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        return {\n","             'ids': torch.tensor(ids, dtype=torch.long),\n","             'mask': torch.tensor(mask, dtype=torch.long),\n","             'targets': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"KCLkuWuIJej-","executionInfo":{"status":"ok","timestamp":1668587392527,"user_tz":-210,"elapsed":4,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["train_dataset = CustomDataset(train, tokenizer, max_len, LABELS_TO_IDS)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"bBjDszroNGY5","executionInfo":{"status":"ok","timestamp":1668587394059,"user_tz":-210,"elapsed":4,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["val_dataset = CustomDataset(val, tokenizer, max_len, LABELS_TO_IDS)"]},{"cell_type":"code","source":["test_dataset = CustomDataset(test, tokenizer, max_len, LABELS_TO_IDS)"],"metadata":{"id":"HEv-q1ZKzRfm","executionInfo":{"status":"ok","timestamp":1668587397817,"user_tz":-210,"elapsed":3,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","execution_count":28,"metadata":{"id":"yLlKzCTkNL4i","executionInfo":{"status":"ok","timestamp":1668587399719,"user_tz":-210,"elapsed":4,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["TRAIN_LOADER = DataLoader(train_dataset, batch_size=train_batch_size)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"IVYxhOEQNPLI","executionInfo":{"status":"ok","timestamp":1668587401401,"user_tz":-210,"elapsed":5,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["VAL_LOADER = DataLoader(val_dataset, batch_size=val_batch_size)"]},{"cell_type":"code","source":["TEST_LOADER = DataLoader(test_dataset, batch_size=test_batch_size)"],"metadata":{"id":"IzqIlc1NzSB5","executionInfo":{"status":"ok","timestamp":1668587402569,"user_tz":-210,"elapsed":4,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1668587432475,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"hp80GbL2NTrs","outputId":"65539e6d-32c1-45bd-f762-dfcfdc4bdff4"},"outputs":[{"output_type":"stream","name":"stdout","text":["228\n","49\n","49\n"]}],"source":["print(len(TRAIN_LOADER))\n","print(len(VAL_LOADER))\n","print(len(TEST_LOADER))"]},{"cell_type":"markdown","source":["##Finetuning"],"metadata":{"id":"wfZv6DN8zn68"}},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["3cacf9338157477bbc5b528bb9afa1f7","1a52097e7a924ec7b79e91cd4b0f55f2","bc7a15e6374b4867a452fd6bf14051e9","fde6739e013d49b2b00b29929a695ac0","b61e43bdbfec47fa9780815bf5bc1373","86099bf20ab94135b3ef7e6523c833d9","17e6a3f3f3f44a4fbc1aa04ed69542d7","214f7088027142529fd847ae6080b5f2","37529e12fdca42c1a8f0a45728f6c78b","64569f0e458440e7ba889f42ca36e5cd","9a7830c9dddd4b589ae822a8eb101bc8","d672e1467ead4fcfb366b2837d4ed68d","0d8a75732b1643e094993b3d4cbd0100","21d50430c5be4011905df8d421c91784","2bec4b910695418fa950b16c2f6988eb","fafa17b1effd4eefaa5877b894924b28","6876d52e22034ee49d3bf92e5e4b9964","cfe7d23b69e14ea0a898a6aa9dcde8c2","d7bc24a3dfee4dd69025ea4c41e37143","335e6b5bfa4841ae94f8838ea8f28baa","94056c21bfef4c2aae1fe756521b180f","1213269548e94b56bc320e123e462157"]},"executionInfo":{"elapsed":22142,"status":"ok","timestamp":1668587471208,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"z5LW4codRvRP","outputId":"18371116-4ed0-4df5-eba9-392f0278544e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cacf9338157477bbc5b528bb9afa1f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/654M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d672e1467ead4fcfb366b2837d4ed68d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertForSequenceClassification.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\", num_labels=len(LABELS_TO_IDS))"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6408,"status":"ok","timestamp":1668587480275,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"},"user_tz":-210},"id":"WbpkuKl4SBSy","outputId":"be80618e-77fc-403d-b9f5-3c13bd2af6bf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(100000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":33}],"source":["model.to(device)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"Kbqc_-bVTRAC","executionInfo":{"status":"ok","timestamp":1668587486214,"user_tz":-210,"elapsed":6,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["epochs = 10\n","learning_rate = 1e-5\n","max_grad_norm = 1e-5\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"xAJBuPRoTcq3","executionInfo":{"status":"ok","timestamp":1668587491056,"user_tz":-210,"elapsed":5,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[],"source":["def calcuate_accu(big_idx, targets):\n","    n_correct = (big_idx == targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZ4Fhav0Thg4"},"outputs":[],"source":["def train(epoch, model, loader, optimizer, loss_function, device):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    y_predict, y_true = [], []\n","    model.train()\n","    #with tqdm(loader, unit='batch') as tepoch:\n","    for _, data in enumerate(tqdm(loader), 0):\n","        # for _, data in tqdm(enumerate(loader, 0)):\n","        ids = data['ids'].to(device, dtype=torch.long)\n","        mask = data['mask'].to(device, dtype=torch.long)\n","        targets = data['targets'].to(device, dtype=torch.long)\n","        \n","        outputs = model(ids, mask)\n","        #outputs = torch.tensor(outputs)\n","        \n","        loss = loss_function(outputs.logits, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.logits, dim=1)\n","        n_correct += calcuate_accu(big_idx, targets)\n","        for y_pred in big_idx.cpu().numpy():\n","             y_predict.append(y_pred)\n","        for y_target in targets.cpu().numpy():\n","             y_true.append(y_target)\n","        nb_tr_steps += 1\n","        nb_tr_examples += targets.size(0)\n","        if _ % 1000 == 0:\n","            loss_step = tr_loss / nb_tr_steps\n","            accu_step = (n_correct * 100) / nb_tr_examples\n","            print(f\"\\nTraining Loss per 1000 steps: {loss_step}\")\n","            f1 = f1_score(y_true, y_predict, average='macro')\n","            print(f\"Training F1-Score per 1000 steps: {f1}\")\n","            # print(f\"Training Accuracy per 1000 steps: {accu_step}\")\n","            print(\"--------------------------------------------------\")\n","        optimizer.zero_grad()\n","        loss.backward()\n","        # # When using GPU\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n","    epoch_loss = tr_loss / nb_tr_steps\n","    epoch_accu = (n_correct * 100) / nb_tr_examples\n","    print(f\"Training Loss Epoch {epoch}: {epoch_loss}\")\n","    f1 = f1_score(y_true, y_predict, average='macro')\n","    print(f\"Training F1-Score {epoch}: {f1}\")\n","    # print(f\"Training Accuracy Epoch {epoch}: {epoch_accu}\")\n"]},{"cell_type":"code","source":["def valid(model, loader, device, dataset_type):\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    n_correct = 0\n","    y_predict = []\n","    y_true = []\n","    model.eval()\n","    with torch.no_grad():\n","        for _, data in enumerate(tqdm(loader), 0):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype=torch.long)\n","            outputs = model(ids, mask)\n","            # try:\n","            big_val, big_idx = torch.max(outputs.logits, dim=1)\n","            # except:\n","            #     print(\"\\n##########################################\")\n","            #     print(f\"Data at: {_}\")\n","            #     print(outputs)\n","            #     print(outputs.data)\n","            #     print(outputs.data.shape)\n","            #     print(\"##########################################\")\n","            #     continue\n","            n_correct += calcuate_accu(big_idx, targets)\n","            for y_pred in big_idx.cpu().numpy():\n","                y_predict.append(y_pred)\n","            for y_target in targets.cpu().numpy():\n","                y_true.append(y_target)\n","            nb_tr_steps += 1\n","            nb_tr_examples += targets.size(0)\n","            if _ % 1000 == 0:\n","                accu_step = (n_correct * 100) / nb_tr_examples\n","                f1 = f1_score(y_true, y_predict, average='macro')\n","                print(f\"\\n{dataset_type} F1-Score {epoch}: {f1}\")\n","                # print(f\"{dataset_type} Accuracy per 1000 steps: {accu_step}\")\n","                print(\"-------------------------------------\")\n","    # epoch_accu = (n_correct * 100) / nb_tr_examples\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n","    epoch_accu = (n_correct * 100) / nb_tr_examples\n","    f1 = f1_score(y_true, y_predict, average='macro')\n","    print(f\"{dataset_type} F1-Score {epoch}: {f1}\")\n","    # print(f\"Training Accuracy Epoch {epoch}: {epoch_accu}\")\n","    print(\"========================================================\")\n","    return y_true, y_predict"],"metadata":{"id":"sZYWfBUm-smg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluation_method(y_true, y_pred, IDS_TO_LABELS):\n","    f1 = f1_score(y_true, y_pred, average='macro')\n","    acc = accuracy_score(y_true, y_pred)\n","    pre = precision_score(y_true, y_pred, average='macro')\n","    rec = recall_score(y_true, y_pred, average='macro')\n","\n","    clf_report = classification_report(y_true, y_pred)\n","    return {\n","        \"y-true\": [IDS_TO_LABELS[y] for y in y_true],\n","        \"y-pred\": [IDS_TO_LABELS[y] for y in y_pred],\n","        \"f1\": f1, \"accuracy\": acc,\n","        \"precision\": pre, \"recall\": rec,\n","        \"clf-report\": clf_report\n","    }"],"metadata":{"id":"iTth3cCD-suW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBJe1Ot-TuKd","outputId":"58beb818-ad7e-4166-9d65-1cd8d4810b38","executionInfo":{"status":"ok","timestamp":1668502485796,"user_tz":-210,"elapsed":1604139,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 1.1162911653518677\n","Training F1-Score per 1000 steps: 0.24725274725274726\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:32<01:56,  1.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:51<00:44,  1.44it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:31<00:04,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:35<00:00,  1.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 0: 54.39031103770988\n","Training Loss Epoch 0: 0.9090867387621027\n","Training F1-Score 0: 0.5295236024582315\n","=================================================================\n","Training epoch: 2\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.8267432451248169\n","Training F1-Score per 1000 steps: 0.5752380952380953\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:07,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:44,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:40<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 1: 64.27195155518855\n","Training Loss Epoch 1: 0.7626524176775363\n","Training F1-Score 1: 0.638138646080524\n","=================================================================\n","Training epoch: 3\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.6703138947486877\n","Training F1-Score per 1000 steps: 0.6511111111111111\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:44,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:40<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 2: 69.76328103495733\n","Training Loss Epoch 2: 0.6586983514328798\n","Training F1-Score 2: 0.6950633545770334\n","=================================================================\n","Training epoch: 4\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.6209123134613037\n","Training F1-Score per 1000 steps: 0.7441231537341378\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:45,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:41<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 3: 75.90145884943573\n","Training Loss Epoch 3: 0.5478836835868526\n","Training F1-Score 3: 0.7583479625600132\n","=================================================================\n","Training epoch: 5\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.43032240867614746\n","Training F1-Score per 1000 steps: 0.846583850931677\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:44,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:41<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 4: 78.02091935039913\n","Training Loss Epoch 4: 0.49720774113870503\n","Training F1-Score 4: 0.778905436628508\n","=================================================================\n","Training epoch: 6\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.478330135345459\n","Training F1-Score per 1000 steps: 0.8753439153439153\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:44,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:40<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 5: 82.35617946600605\n","Training Loss Epoch 5: 0.42029936271801327\n","Training F1-Score 5: 0.8227140499943465\n","=================================================================\n","Training epoch: 7\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.560843825340271\n","Training F1-Score per 1000 steps: 0.8422753716871364\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.40it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:44,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:40<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 6: 85.43903110377099\n","Training Loss Epoch 6: 0.35219063786299604\n","Training F1-Score 6: 0.8536491252493962\n","=================================================================\n","Training epoch: 8\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.18520888686180115\n","Training F1-Score per 1000 steps: 0.9696342305037957\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:44,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:40<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 7: 86.89788053949904\n","Training Loss Epoch 7: 0.32539518170973714\n","Training F1-Score 7: 0.868532275052799\n","=================================================================\n","Training epoch: 9\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.3829719126224518\n","Training F1-Score per 1000 steps: 0.8063492063492063\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:44,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:40<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 8: 89.6091384530691\n","Training Loss Epoch 8: 0.26680640581374365\n","Training F1-Score 8: 0.8955882448603391\n","=================================================================\n","Training epoch: 10\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/228 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Training Loss per 1000 steps: 0.16702842712402344\n","Training F1-Score per 1000 steps: 0.9388888888888888\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 47/228 [00:33<02:08,  1.41it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 72%|███████▏  | 164/228 [01:56<00:45,  1.42it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"," 97%|█████████▋| 221/228 [02:36<00:04,  1.43it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 228/228 [02:40<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 9: 92.16900633085604\n","Training Loss Epoch 9: 0.19574434336748692\n","Training F1-Score 9: 0.921245303870532\n","=================================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["for epoch in range(epochs):\n","  print(f\"Training epoch: {epoch + 1}\")\n","  train(epoch, model, TRAIN_LOADER, optimizer, loss_fn, device)\n","  print(\"=================================================================\")"]},{"cell_type":"code","source":["print(\"*********************************VAL******************************\")\n","y_val_true, y_val_pred = valid(model, VAL_LOADER, device, \"Validation\")\n","print(\"*********************************TEST******************************\")\n","y_test_true, y_test_pred = valid(model, TEST_LOADER, device, \"Test\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRh68zgx7A8Q","executionInfo":{"status":"ok","timestamp":1668502635525,"user_tz":-210,"elapsed":25936,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}},"outputId":"cbb102c4-796a-4305-aa26-da7a88e74b7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["*********************************DEV******************************\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/49 [00:00<00:15,  3.18it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Validation F1-Score 9: 0.7260245475348451\n","-------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 49/49 [00:12<00:00,  3.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 9: 64.73649967469096\n","Validation F1-Score 9: 0.6425456936078208\n","========================================================\n","*********************************TEST******************************\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 1/49 [00:00<00:12,  3.92it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Test F1-Score 9: 0.7822076978939724\n","-------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 11/49 [00:02<00:09,  3.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n","100%|██████████| 49/49 [00:12<00:00,  3.79it/s]"]},{"output_type":"stream","name":"stdout","text":["The Total Accuracy for Epoch 9: 66.43222506393862\n","Test F1-Score 9: 0.6612468649906876\n","========================================================\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["results = {\n","        \"val\": evaluation_method(y_val_true, y_val_pred, IDS_TO_LABELS),\n","        \"test\": evaluation_method(y_test_true, y_test_pred, IDS_TO_LABELS)\n","    }\n","print(f\"VAL, F1-Score: {results['val']['f1']}, Accuracy: {results['val']['accuracy']}\")\n","print(f\"TEST, F1-Score: {results['test']['f1']}, Accuracy: {results['test']['accuracy']}\")"],"metadata":{"id":"b31E-IW77WpB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668502789821,"user_tz":-210,"elapsed":11,"user":{"displayName":"mahsa sanaei","userId":"09052074905704490784"}},"outputId":"0405aa74-647d-4616-e698-83fe671a5e2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VAL, F1-Score: 0.6425456936078208, Accuracy: 0.6473649967469096\n","TEST, F1-Score: 0.6612468649906876, Accuracy: 0.6643222506393862\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GJ9hvtOIhBk2"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOVeZ7pBl3om2fjCfGELdz0"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"734720fed4fc4f37b30bbab21d408196":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f6de2a1f2c848d1bf84666fde36960d","IPY_MODEL_3450f318c8d54bbe916708c75d83aea3","IPY_MODEL_dcfe3f8d05eb4f06a372eef7e75689cd"],"layout":"IPY_MODEL_590d989e8e344abe8bf45cc6a16b9224"}},"0f6de2a1f2c848d1bf84666fde36960d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84f1109546ca41209eb29e48ebf568a8","placeholder":"​","style":"IPY_MODEL_8eaf32825a4745f687410bd7cedf127a","value":"Downloading: 100%"}},"3450f318c8d54bbe916708c75d83aea3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6a2dcf306a24672810df589da799398","max":1215509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b125f273e494c8e9f717f5edd99e6d9","value":1215509}},"dcfe3f8d05eb4f06a372eef7e75689cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_798ff23a32c641e49206d73382d81d1d","placeholder":"​","style":"IPY_MODEL_ce16cb36025043409bf47502078f7854","value":" 1.22M/1.22M [00:00&lt;00:00, 16.5MB/s]"}},"590d989e8e344abe8bf45cc6a16b9224":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84f1109546ca41209eb29e48ebf568a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eaf32825a4745f687410bd7cedf127a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6a2dcf306a24672810df589da799398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b125f273e494c8e9f717f5edd99e6d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"798ff23a32c641e49206d73382d81d1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce16cb36025043409bf47502078f7854":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2243c5125424610a684e984389fedba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b3ffcb6b5c84e4295905b8db65d7f43","IPY_MODEL_2d8cfc6cf7b14e70982c03ce05a59596","IPY_MODEL_a3926770478547c3b48950c1e7b9ab8f"],"layout":"IPY_MODEL_feef64b87bd549a783535d1d38ce690c"}},"4b3ffcb6b5c84e4295905b8db65d7f43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fea59c806d8471c8268e73571d2682a","placeholder":"​","style":"IPY_MODEL_aea8d8aec1f14ff3af42fe49b0be4db4","value":"Downloading: 100%"}},"2d8cfc6cf7b14e70982c03ce05a59596":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb3965e51c0c40f1990b65385dd5ab07","max":434,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61f08537449f464a9a274b3fbcbda789","value":434}},"a3926770478547c3b48950c1e7b9ab8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba9a8633883c4d2fb76a7d63cde23aad","placeholder":"​","style":"IPY_MODEL_146f08edaf2742d48f7fa5ca93d4dbe4","value":" 434/434 [00:00&lt;00:00, 12.9kB/s]"}},"feef64b87bd549a783535d1d38ce690c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fea59c806d8471c8268e73571d2682a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea8d8aec1f14ff3af42fe49b0be4db4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb3965e51c0c40f1990b65385dd5ab07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61f08537449f464a9a274b3fbcbda789":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba9a8633883c4d2fb76a7d63cde23aad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"146f08edaf2742d48f7fa5ca93d4dbe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cacf9338157477bbc5b528bb9afa1f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a52097e7a924ec7b79e91cd4b0f55f2","IPY_MODEL_bc7a15e6374b4867a452fd6bf14051e9","IPY_MODEL_fde6739e013d49b2b00b29929a695ac0"],"layout":"IPY_MODEL_b61e43bdbfec47fa9780815bf5bc1373"}},"1a52097e7a924ec7b79e91cd4b0f55f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86099bf20ab94135b3ef7e6523c833d9","placeholder":"​","style":"IPY_MODEL_17e6a3f3f3f44a4fbc1aa04ed69542d7","value":"Downloading: 100%"}},"bc7a15e6374b4867a452fd6bf14051e9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_214f7088027142529fd847ae6080b5f2","max":440,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37529e12fdca42c1a8f0a45728f6c78b","value":440}},"fde6739e013d49b2b00b29929a695ac0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64569f0e458440e7ba889f42ca36e5cd","placeholder":"​","style":"IPY_MODEL_9a7830c9dddd4b589ae822a8eb101bc8","value":" 440/440 [00:00&lt;00:00, 8.55kB/s]"}},"b61e43bdbfec47fa9780815bf5bc1373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86099bf20ab94135b3ef7e6523c833d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17e6a3f3f3f44a4fbc1aa04ed69542d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"214f7088027142529fd847ae6080b5f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37529e12fdca42c1a8f0a45728f6c78b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64569f0e458440e7ba889f42ca36e5cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a7830c9dddd4b589ae822a8eb101bc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d672e1467ead4fcfb366b2837d4ed68d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d8a75732b1643e094993b3d4cbd0100","IPY_MODEL_21d50430c5be4011905df8d421c91784","IPY_MODEL_2bec4b910695418fa950b16c2f6988eb"],"layout":"IPY_MODEL_fafa17b1effd4eefaa5877b894924b28"}},"0d8a75732b1643e094993b3d4cbd0100":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6876d52e22034ee49d3bf92e5e4b9964","placeholder":"​","style":"IPY_MODEL_cfe7d23b69e14ea0a898a6aa9dcde8c2","value":"Downloading: 100%"}},"21d50430c5be4011905df8d421c91784":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7bc24a3dfee4dd69025ea4c41e37143","max":654226731,"min":0,"orientation":"horizontal","style":"IPY_MODEL_335e6b5bfa4841ae94f8838ea8f28baa","value":654226731}},"2bec4b910695418fa950b16c2f6988eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94056c21bfef4c2aae1fe756521b180f","placeholder":"​","style":"IPY_MODEL_1213269548e94b56bc320e123e462157","value":" 654M/654M [00:19&lt;00:00, 33.3MB/s]"}},"fafa17b1effd4eefaa5877b894924b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6876d52e22034ee49d3bf92e5e4b9964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfe7d23b69e14ea0a898a6aa9dcde8c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7bc24a3dfee4dd69025ea4c41e37143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"335e6b5bfa4841ae94f8838ea8f28baa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94056c21bfef4c2aae1fe756521b180f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1213269548e94b56bc320e123e462157":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}